{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-26T09:57:27.722267Z","iopub.execute_input":"2022-06-26T09:57:27.723545Z","iopub.status.idle":"2022-06-26T09:57:36.194966Z","shell.execute_reply.started":"2022-06-26T09:57:27.723372Z","shell.execute_reply":"2022-06-26T09:57:36.193547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# IMPORTS","metadata":{}},{"cell_type":"code","source":"pip install einops","metadata":{"execution":{"iopub.status.busy":"2022-06-26T09:57:59.934152Z","iopub.execute_input":"2022-06-26T09:57:59.934625Z","iopub.status.idle":"2022-06-26T09:58:11.761105Z","shell.execute_reply.started":"2022-06-26T09:57:59.934581Z","shell.execute_reply":"2022-06-26T09:58:11.759334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom einops import rearrange, repeat\nfrom einops.layers.torch import Rearrange\nfrom typing import List, Union\nfrom pathlib import Path\nfrom torch.utils.data import random_split\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nimport torchvision.datasets as dset\nimport torchvision.transforms as transforms\nimport torch.optim as optim\nimport time\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision.io import read_image\nfrom torchvision import transforms\nimport matplotlib.pyplot as plt\nfrom torchvision import datasets\nfrom torch.optim import Adam\nfrom sklearn.model_selection import train_test_split\nimport csv\nimport os","metadata":{"execution":{"iopub.status.busy":"2022-06-26T09:58:13.162793Z","iopub.execute_input":"2022-06-26T09:58:13.163247Z","iopub.status.idle":"2022-06-26T09:58:13.860886Z","shell.execute_reply.started":"2022-06-26T09:58:13.16321Z","shell.execute_reply":"2022-06-26T09:58:13.859919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CARGAR DATOS","metadata":{}},{"cell_type":"code","source":"dataset = datasets.ImageFolder('/kaggle/input/iais22-birds/birds/birds/', transform=transforms.Compose([transforms.Resize((64,64)), transforms.ToTensor()]))\ntrain_set, val_set = random_split(dataset, (int(len(dataset) * 0.9) + 1, int(len(dataset) * 0.1)))","metadata":{"execution":{"iopub.status.busy":"2022-06-26T17:01:57.135154Z","iopub.execute_input":"2022-06-26T17:01:57.13568Z","iopub.status.idle":"2022-06-26T17:01:57.820969Z","shell.execute_reply.started":"2022-06-26T17:01:57.135637Z","shell.execute_reply":"2022-06-26T17:01:57.818744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = DataLoader(dataset, batch_size=200, shuffle=True)\ntrain_dataloader = DataLoader(train_set, batch_size=200, shuffle=True)\nval_dataloader = DataLoader(val_set, batch_size=200, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T17:02:01.594125Z","iopub.execute_input":"2022-06-26T17:02:01.594593Z","iopub.status.idle":"2022-06-26T17:02:01.602673Z","shell.execute_reply.started":"2022-06-26T17:02:01.594551Z","shell.execute_reply":"2022-06-26T17:02:01.601202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CREACIÓN DEL MODELO","metadata":{}},{"cell_type":"markdown","source":"HELPERS","metadata":{}},{"cell_type":"code","source":"def pair(t):\n    return t if isinstance(t, tuple) else (t, t)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T17:02:04.554297Z","iopub.execute_input":"2022-06-26T17:02:04.555491Z","iopub.status.idle":"2022-06-26T17:02:04.560952Z","shell.execute_reply.started":"2022-06-26T17:02:04.555426Z","shell.execute_reply":"2022-06-26T17:02:04.559869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"CLASSES","metadata":{}},{"cell_type":"code","source":"class PreNorm(nn.Module):\n    def __init__(self, dim, fn):\n        super().__init__()\n        self.norm = nn.LayerNorm(dim)\n        self.fn = fn\n    def forward(self, x, **kwargs):\n        return self.fn(self.norm(x), **kwargs)\n\nclass MLP(nn.Module):\n    def __init__(self, dim, hidden_dim, dropout = 0.):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(dim, hidden_dim),\n            nn.GELU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_dim, dim),\n            nn.Dropout(dropout)\n        )\n    def forward(self, x):\n        return self.net(x)\n\nclass Attention(nn.Module):\n    def __init__(self, dim, heads = 8, dim_head = 64, dropout = 0.):\n        super().__init__()\n        inner_dim = dim_head *  heads #Dimension interna\n        project_out = not (heads == 1 and dim_head == dim)\n\n        self.heads = heads\n        self.scale = dim_head ** -0.5 #Divide a la mitad\n\n        self.attend = nn.Softmax(dim = -1) #Aplicamos funcion softmax\n        self.dropout = nn.Dropout(dropout) #Limpia la red\n\n        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = False) #Obtiene los valores de q, k, v\n\n        self.to_out = nn.Sequential(\n            nn.Linear(inner_dim, dim),\n            nn.Dropout(dropout)\n        ) if project_out else nn.Identity()\n\n    def forward(self, x):\n        qkv = self.to_qkv(x).chunk(3, dim = -1) #Crea las variables q, k, v. con chunk divide el tensor en tres fragmentos\n        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = self.heads), qkv) #Las reordena para poder usarlas mejor como operadores\n\n        dots = torch.matmul(q, k.transpose(-1, -2)) * self.scale #Multiplica el vector Q por K traspuesta cambiando la primera fila y segunda fula por la última y la penultima\n\n        attn = self.attend(dots) #Aplica softmax\n        attn = self.dropout(attn) #Evita overfitting\n\n        out = torch.matmul(attn, v) #Multiplica el resultado de aplicar softmax por V\n        out = rearrange(out, 'b h n d -> b n (h d)') #Las vuelve a reordenar para que la salida sea normal\n        return self.to_out(out)\n\nclass Encoder(nn.Module):\n    def __init__(self, dim, depth, heads, dim_head, mlp_dim, dropout = 0.):\n        super().__init__()\n        self.layers = nn.ModuleList([])\n        for _ in range(depth):\n            self.layers.append(nn.ModuleList([\n                PreNorm(dim, Attention(dim, heads = heads, dim_head = dim_head, dropout = dropout)),\n                PreNorm(dim, MLP(dim, mlp_dim, dropout = dropout))\n            ]))\n    def forward(self, x):\n        for attn, ff in self.layers:\n            x = attn(x) + x\n            x = ff(x) + x\n        return x\n\nclass ViT(nn.Module):\n    def __init__(self, *, image_size, patch_size, num_classes, dim, depth, heads, mlp_dim, pool = 'cls', channels = 3, dim_head = 64, dropout = 0., emb_dropout = 0.):\n        super().__init__()\n        #Obtiene la altura y el ancho de la imagen\n        image_height, image_width = pair(image_size)\n        #Obtiene la altura y el ancho del patch\n        patch_height, patch_width = pair(patch_size)\n        \n        #Comprueba que la altura de la imagen sea divisible por la altura del patch y lo mismo con el ancho\n        assert image_height % patch_height == 0 and image_width % patch_width == 0, 'Image dimensions must be divisible by the patch size.'\n        \n        #Obtiene el numero de veces en el que se ha dividido la imagen\n        num_patches = (image_height // patch_height) * (image_width // patch_width)\n        #Las dimensiones de cad subtrozo de imagen\n        patch_dim = channels * patch_height * patch_width\n        assert pool in {'cls', 'mean'}, 'pool type must be either cls (cls token) or mean (mean pooling)'\n        \n        #Capa EMBEDDED PATCHES\n        self.to_patch_embedding = nn.Sequential(\n            Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1 = patch_height, p2 = patch_width),\n            nn.Linear(patch_dim, dim),\n        )\n\n        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dim))\n        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n        self.dropout = nn.Dropout(emb_dropout)\n\n        #ENCODER\n        self.encoder = Encoder(dim, depth, heads, dim_head, mlp_dim, dropout)\n\n        self.pool = pool\n        self.to_latent = nn.Identity()\n        \n        #MLP HEAD\n        self.mlp_head = nn.Sequential(\n            nn.LayerNorm(dim),\n            nn.Linear(dim, num_classes)\n        )\n\n    def forward(self, img):\n        #EMBEDDED PATCHES\n        x = self.to_patch_embedding(img)\n        b, n, _ = x.shape\n        cls_tokens = repeat(self.cls_token, '1 n d -> b n d', b = b)\n        x = torch.cat((cls_tokens, x), dim=1)\n        x += self.pos_embedding[:, :(n + 1)]\n        x = self.dropout(x)\n        \n        #Se aplica el ENCODER\n        x = self.encoder(x)\n        \n        #Si se ha declarado que se use la media se usa, si no, se toma la primera columna\n        x = x.mean(dim = 1) if self.pool == 'mean' else x[:, 0]\n        \n        #Función de activación la identidad\n        x = self.to_latent(x)\n        return self.mlp_head(x)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T17:02:05.38172Z","iopub.execute_input":"2022-06-26T17:02:05.382149Z","iopub.status.idle":"2022-06-26T17:02:05.414272Z","shell.execute_reply.started":"2022-06-26T17:02:05.382112Z","shell.execute_reply":"2022-06-26T17:02:05.412616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"Using {device} device\")","metadata":{"execution":{"iopub.status.busy":"2022-06-26T17:02:06.106268Z","iopub.execute_input":"2022-06-26T17:02:06.107486Z","iopub.status.idle":"2022-06-26T17:02:06.115913Z","shell.execute_reply.started":"2022-06-26T17:02:06.107422Z","shell.execute_reply":"2022-06-26T17:02:06.114653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = ViT(\n    image_size = 64,\n    patch_size = 8,\n    num_classes = 400,\n    dim = 256,\n    depth = 2,\n    heads = 8,\n    mlp_dim = 512,\n    dropout = 0.1,\n    emb_dropout = 0.1\n)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T17:02:06.664449Z","iopub.execute_input":"2022-06-26T17:02:06.6649Z","iopub.status.idle":"2022-06-26T17:02:06.689623Z","shell.execute_reply.started":"2022-06-26T17:02:06.664861Z","shell.execute_reply":"2022-06-26T17:02:06.688317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learning_rate = 1e-3\n\nloss_fn = nn.CrossEntropyLoss()\noptimizer = Adam(params=model.parameters(), lr=learning_rate, amsgrad=False)\n\n\ndef train_loop(dataloader, model, loss_fn, optimizer):\n    size = len(dataloader.dataset)\n    for batch, (X, y) in enumerate(dataloader):\n        # Compute prediction and loss\n        pred = model(X)\n        loss = loss_fn(pred, y)\n\n        # Backpropagation\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        if batch % 100 == 0:\n            loss, current = loss.item(), batch * len(X)\n            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n\n\ndef test_loop(dataloader, model, loss_fn):\n    size = len(dataloader.dataset)\n    num_batches = len(dataloader)\n    test_loss, correct = 0, 0\n\n    with torch.no_grad():\n        for X, y in dataloader:\n            pred = model(X)\n            test_loss += loss_fn(pred, y).item()\n            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n\n    test_loss /= num_batches\n    correct /= size\n    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n    \n    \n\n\nepochs = 15\nfor t in range(epochs):\n    print(f\"Epoch {t+1}\\n-------------------------------\")\n    train_loop(train, model, loss_fn, optimizer)\n    test_loop(val_dataloader, model, loss_fn)\nprint(\"Done!\")","metadata":{"execution":{"iopub.status.busy":"2022-06-26T17:02:29.632477Z","iopub.execute_input":"2022-06-26T17:02:29.632901Z","iopub.status.idle":"2022-06-26T20:23:59.377323Z","shell.execute_reply.started":"2022-06-26T17:02:29.632867Z","shell.execute_reply":"2022-06-26T20:23:59.373063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PATH = './modelo_seleccionado.pth'\ntorch.save(model.state_dict(), PATH)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T20:30:17.134477Z","iopub.execute_input":"2022-06-26T20:30:17.136675Z","iopub.status.idle":"2022-06-26T20:30:17.182036Z","shell.execute_reply.started":"2022-06-26T20:30:17.136527Z","shell.execute_reply":"2022-06-26T20:30:17.180623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"red = ViT(\n    image_size = 64,\n    patch_size = 8,\n    num_classes = 400,\n    dim = 256,\n    depth = 2,\n    heads = 8,\n    mlp_dim = 512,\n    dropout = 0.1,\n    emb_dropout = 0.1\n)\nred.load_state_dict(torch.load(PATH))","metadata":{"execution":{"iopub.status.busy":"2022-06-26T20:30:34.148391Z","iopub.execute_input":"2022-06-26T20:30:34.14993Z","iopub.status.idle":"2022-06-26T20:30:34.21113Z","shell.execute_reply.started":"2022-06-26T20:30:34.149852Z","shell.execute_reply":"2022-06-26T20:30:34.209562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\nclass BirdsDatasetTest(torch.utils.data.Dataset):\n    def __init__(self, path: Union[Path, str],\n                transform: Union['Transform', List['Transform']] = transforms.Compose([transforms.Resize((64,64)),transforms.ToTensor()])):\n        self.path = Path(path)\n        self.labels = [p.name for p in path.glob('x')]\n        self.images = list(path.glob('*/*.jpg'))\n        self.transform = transform\n        \n    \n    def __len__(self) -> int:\n        return len(self.images)\n    \n    def __getitem__(self, index:int) :\n        image_path = self.images[index]\n        image = self.transform(Image.open(str(image_path)))\n        archivo = os.path.basename(image_path)\n        id = archivo.split(sep=\".\")[0]\n        return image,id","metadata":{"execution":{"iopub.status.busy":"2022-06-26T20:30:34.466137Z","iopub.execute_input":"2022-06-26T20:30:34.466878Z","iopub.status.idle":"2022-06-26T20:30:34.483943Z","shell.execute_reply.started":"2022-06-26T20:30:34.466836Z","shell.execute_reply":"2022-06-26T20:30:34.482278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dat = BirdsDatasetTest(path = Path('/kaggle/input/iais22-birds/submission_test/'))\nclases = dataset.classes\ndataloader = DataLoader(test_dat, batch_size=1)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T20:30:35.334657Z","iopub.execute_input":"2022-06-26T20:30:35.335319Z","iopub.status.idle":"2022-06-26T20:30:35.472127Z","shell.execute_reply.started":"2022-06-26T20:30:35.335276Z","shell.execute_reply":"2022-06-26T20:30:35.470976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('submission.csv', 'w') as csvfile:\n    fieldnames = ['Id', 'Category']\n    writer = csv.DictWriter(csvfile, fieldnames = fieldnames)\n    writer.writeheader()\n    for image,id in dataloader:\n        pred = red(image)\n        categoria = clases[pred.argmax(1)]\n        writer.writerow({'Id': int(id[0]), 'Category': categoria})","metadata":{"execution":{"iopub.status.busy":"2022-06-26T20:30:36.11205Z","iopub.execute_input":"2022-06-26T20:30:36.112727Z","iopub.status.idle":"2022-06-26T20:31:04.3022Z","shell.execute_reply.started":"2022-06-26T20:30:36.112687Z","shell.execute_reply":"2022-06-26T20:31:04.300839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}